{"cells":[{"cell_type":"code","source":"import pandas as _hex_pandas\nimport datetime as _hex_datetime\nimport json as _hex_json","execution_count":null,"metadata":{},"outputs":[]},{"cell_type":"code","source":"hex_scheduled = _hex_json.loads(\"false\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_user_email = _hex_json.loads(\"\\\"example-user@example.com\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_run_context = _hex_json.loads(\"\\\"logic\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_timezone = _hex_json.loads(\"\\\"UTC\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_project_id = _hex_json.loads(\"\\\"ed7149ad-9ca0-4662-a838-a0ec735ec38b\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_color_palette = _hex_json.loads(\"[\\\"#4C78A8\\\",\\\"#F58518\\\",\\\"#E45756\\\",\\\"#72B7B2\\\",\\\"#54A24B\\\",\\\"#EECA3B\\\",\\\"#B279A2\\\",\\\"#FF9DA6\\\",\\\"#9D755D\\\",\\\"#BAB0AC\\\"]\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"source_df_path = _hex_json.loads(\"\\\"disasters_1970_2021.csv\\\"\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install langchain tabulate openai python-dotenv","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"Collecting langchain\n  Downloading langchain-0.0.196-py3-none-any.whl (1.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tabulate in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.10/lib/python3.10/site-packages (0.8.10)\nRequirement already satisfied: openai in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.10/lib/python3.10/site-packages (0.27.2)\nCollecting python-dotenv\n  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\nRequirement already satisfied: PyYAML>=5.4.1 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.10/lib/python3.10/site-packages (from langchain) (6.0)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.10/lib/python3.10/site-packages (from langchain) (1.4.41)\nCollecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.10/lib/python3.10/site-packages (from langchain) (4.0.2)\nCollecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\nCollecting langchainplus-sdk>=0.0.7 (from langchain)\n  Downloading langchainplus_sdk-0.0.8-py3-none-any.whl (22 kB)\nCollecting numexpr<3.0.0,>=2.8.4 (from langchain)\n  Downloading numexpr-2.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (381 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.4/381.4 kB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.10/lib/python3.10/site-packages (from langchain) (1.23.4)\nCollecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.10/lib/python3.10/site-packages (from langchain) (1.10.6)\nRequirement already satisfied: requests<3,>=2 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.10/lib/python3.10/site-packages (from langchain) (2.28.1)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.10/lib/python3.10/site-packages (from langchain) (8.1.0)\nRequirement already satisfied: tqdm in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.10/lib/python3.10/site-packages (from openai) (4.64.1)\nRequirement already satisfied: attrs>=17.3.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.1.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.10/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.18.0)\nCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\nCollecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\nRequirement already satisfied: typing-extensions>=4.2.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.10/lib/python3.10/site-packages (from pydantic<2,>=1->langchain) (4.6.3)\nRequirement already satisfied: idna<4,>=2.5 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.12)\nRequirement already satisfied: certifi>=2017.4.17 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2022.9.24)\nRequirement already satisfied: greenlet!=0.4.17 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.10/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.3)\nRequirement already satisfied: packaging>=17.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.10/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.10/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (0.4.3)\nInstalling collected packages: typing-inspect, python-dotenv, numexpr, openapi-schema-pydantic, marshmallow-enum, langchainplus-sdk, aiohttp, dataclasses-json, langchain\n  Attempting uninstall: numexpr\n    Found existing installation: numexpr 2.8.3\n    Uninstalling numexpr-2.8.3:\n      Successfully uninstalled numexpr-2.8.3\n  Attempting uninstall: aiohttp\n    Found existing installation: aiohttp 3.8.1\n    Uninstalling aiohttp-3.8.1:\n      Successfully uninstalled aiohttp-3.8.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngremlinpython 3.6.1 requires aiohttp<=3.8.1,>=3.8.0, but you have aiohttp 3.8.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed aiohttp-3.8.4 dataclasses-json-0.5.7 langchain-0.0.196 langchainplus-sdk-0.0.8 marshmallow-enum-1.5.1 numexpr-2.8.4 openapi-schema-pydantic-1.2.4 python-dotenv-1.0.0 typing-inspect-0.9.0\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"import pandas as pd\nfrom langchain.agents import create_pandas_dataframe_agent, load_tools\nfrom langchain import OpenAI\nfrom dotenv import find_dotenv, load_dotenv\nimport os\nimport re\nload_dotenv(find_dotenv())\n\ndef run_query(df, query, openai_key=None,):\n    llm = OpenAI(\n        openai_api_key=\"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\",\n        model_name=\"gpt-3.5-turbo\",\n    )\n    tools = load_tools(\n        [\"llm-math\", \"open-meteo-api\", \"requests_all\", \"terminal\", \"python_repl\"],\n        llm=llm,\n    )\n\n    agent = create_pandas_dataframe_agent(\n        llm=llm,\n        df=df,\n        tools=tools,\n        verbose=True,\n        max_iterations=10,\n        max_execution_time=15,\n    )\n\n    prompt_template = \"\"\"\n    You are a helpful assistant that that can answer questions \\\n    in an a step by step way, making sure to have the right answer. \\\n    Let's work out the following problem: \\\n        \n    {prompt}. \n    Now, as a researcher, you are tasked with investigating the provided response options, \\\n    list the flaws and faulty logic, as well as the correct statements of each answer option.\\\n    Let's work out step in a step by step way to be sure we have all the errors and correct statements. \\\n    Then, after discussing the reseached options, as a resolver, you are tasked with 1) finding which of \\\n    the answer the reseacher though of was best, 2) improving that answer, and 3) returning the improved answer in full. \\\n    Let's work this out in a step by step way to be sure we have the right answer. \\\n    At the end, return a user friendly answer as per the initial question following the result result of step 3. \\\n    \"\"\"    \n\n    try:\n        response= agent.run(query)#prompt_template.format(prompt=query))\n        \n    except Exception as e:\n             response = str(e)\n             if response.startswith(\"Could not parse LLM output: `\"):\n                  response = response.removeprefix(\"Could not parse LLM output: `\").removesuffix(\"`\")\n    \n    return response","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import requests\n\ndef get_all_countries():\n    url = \"https://restcountries.com/v2/all\"\n    response = requests.get(url)\n    data = response.json()\n\n    country_lat_long = {}\n\n    for country in data:\n        name = country['name']\n        latlng = country.get('latlng', [])\n        if len(latlng) == 2:\n            country_lat_long[name] = tuple(latlng)\n\n    return country_lat_long\n\ndef add_lat_long(df, countries):\n    # Check if 'Country' is in dataframe columns\n    if 'Country' not in df.columns:\n        raise ValueError(\"DataFrame must contain a 'Country' column.\")\n\n    # Create separate lists for lat and long\n    df['lat'] = df['Country'].apply(lambda x: countries[x][0] if x in countries else np.nan)\n    df['long'] = df['Country'].apply(lambda x: countries[x][1] if x in countries else np.nan)\n    \n    return df\n\ncountries = get_all_countries()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pandasql as ps\npd_df = pd.read_csv(source_df_path)\npd_df = add_lat_long(pd_df, countries)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import jinja2\n# raw_query = \"\"\"\n#     select * from pd_df\n# \"\"\"\n# sql_query = jinja2.Template(raw_query).render(vars())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = _hex_json.loads(\"\\\"what is the sum of deaths in china\\\"\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nresponse = run_query(df=pd_df, query=query)","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.10/lib/python3.10/site-packages/langchain/llms/openai.py:171: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.10/lib/python3.10/site-packages/langchain/llms/openai.py:739: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n  warnings.warn(\n\n\n\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n\u001b[32;1m\u001b[1;3mThought: I need to filter the dataframe to only include records where the country is China, then sum up the Total Deaths column for those records.\nAction: python_repl_ast\nAction Input:\n```\nchina_df = df[df['Country']=='China']\nchina_deaths_sum = china_df['Total Deaths'].sum()\nprint(china_deaths_sum)\n```\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m458408.0\n\u001b[0m\nThought:\u001b[32;1m\u001b[1;3mI now know the final answer\nFinal Answer: The sum of deaths in China is 458,408.\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"print(response)","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"The sum of deaths in China is 458,408.\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"countries_df = ps.sqldf(\"\"\"select distinct Country from pd_df\"\"\", locals())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"disaster_type_df = ps.sqldf(\"\"\"select distinct \"Disaster Type\" from pd_df\"\"\", locals())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"end_date = None","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_date = None","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json as _hex_json\ndisasters_type = _hex_pks.kernel_execution.input_cell.run_multiselect_dynamic(args=_hex_types.MultiselectDynamicArgs.from_dict({**_hex_json.loads(\"{\\\"dataframe_column\\\":\\\"Disaster Type\\\",\\\"select_all\\\":true}\"), **{_hex_json.loads(\"\\\"options_variable\\\"\"):_hex_kernel.variable_or_none(\"disaster_type_df\", scope_getter=lambda: globals()), _hex_json.loads(\"\\\"ui_selected_values\\\"\"):[]}}), app_session_token=_hex_APP_SESSION_TOKEN, python_kernel_init_status=_hex_python_kernel_init_status, hex_timezone=_hex_kernel.variable_or_none(\"hex_timezone\", scope_getter=lambda: globals()))\n\nimport json as _hex_json\n_hex_pks.kernel_execution.input_cell.filled_dynamic_value(args=_hex_types.FilledDynamicValueArgs.from_dict({**_hex_json.loads(\"{\\\"variable_name\\\":\\\"disaster_type_df\\\",\\\"max_size\\\":10000,\\\"dataframe_column\\\":\\\"Disaster Type\\\",\\\"max_size_in_bytes\\\":5242880}\"), **{_hex_json.loads(\"\\\"variable\\\"\"):_hex_kernel.variable_or_none(\"disaster_type_df\", scope_getter=lambda: globals())}}), app_session_token=_hex_APP_SESSION_TOKEN, python_kernel_init_status=_hex_python_kernel_init_status, hex_timezone=_hex_kernel.variable_or_none(\"hex_timezone\", scope_getter=lambda: globals()))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json as _hex_json\ncountries_selection = _hex_pks.kernel_execution.input_cell.run_multiselect_dynamic(args=_hex_types.MultiselectDynamicArgs.from_dict({**_hex_json.loads(\"{\\\"dataframe_column\\\":\\\"Country\\\",\\\"select_all\\\":true}\"), **{_hex_json.loads(\"\\\"options_variable\\\"\"):_hex_kernel.variable_or_none(\"countries_df\", scope_getter=lambda: globals()), _hex_json.loads(\"\\\"ui_selected_values\\\"\"):[]}}), app_session_token=_hex_APP_SESSION_TOKEN, python_kernel_init_status=_hex_python_kernel_init_status, hex_timezone=_hex_kernel.variable_or_none(\"hex_timezone\", scope_getter=lambda: globals()))\n\nimport json as _hex_json\n_hex_pks.kernel_execution.input_cell.filled_dynamic_value(args=_hex_types.FilledDynamicValueArgs.from_dict({**_hex_json.loads(\"{\\\"variable_name\\\":\\\"countries_df\\\",\\\"max_size\\\":10000,\\\"dataframe_column\\\":\\\"Country\\\",\\\"max_size_in_bytes\\\":5242880}\"), **{_hex_json.loads(\"\\\"variable\\\"\"):_hex_kernel.variable_or_none(\"countries_df\", scope_getter=lambda: globals())}}), app_session_token=_hex_APP_SESSION_TOKEN, python_kernel_init_status=_hex_python_kernel_init_status, hex_timezone=_hex_kernel.variable_or_none(\"hex_timezone\", scope_getter=lambda: globals()))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json as _hex_json\nstart_year = _hex_pks.kernel_execution.input_cell.run_dropdown_dynamic(args=_hex_types.DropdownDynamicArgs.from_dict({**_hex_json.loads(\"{\\\"dataframe_column\\\":\\\"Year\\\",\\\"ui_selected_value\\\":2017}\"), **{_hex_json.loads(\"\\\"options_variable\\\"\"):_hex_kernel.variable_or_none(\"years_list\", scope_getter=lambda: globals())}}), app_session_token=_hex_APP_SESSION_TOKEN, python_kernel_init_status=_hex_python_kernel_init_status, hex_timezone=_hex_kernel.variable_or_none(\"hex_timezone\", scope_getter=lambda: globals()))\n\nimport json as _hex_json\n_hex_pks.kernel_execution.input_cell.filled_dynamic_value(args=_hex_types.FilledDynamicValueArgs.from_dict({**_hex_json.loads(\"{\\\"variable_name\\\":\\\"years_list\\\",\\\"dataframe_column\\\":\\\"Year\\\",\\\"max_size\\\":10000,\\\"max_size_in_bytes\\\":5242880}\"), **{_hex_json.loads(\"\\\"variable\\\"\"):_hex_kernel.variable_or_none(\"years_list\", scope_getter=lambda: globals())}}), app_session_token=_hex_APP_SESSION_TOKEN, python_kernel_init_status=_hex_python_kernel_init_status, hex_timezone=_hex_kernel.variable_or_none(\"hex_timezone\", scope_getter=lambda: globals()))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json as _hex_json\nend_year = _hex_pks.kernel_execution.input_cell.run_dropdown_dynamic(args=_hex_types.DropdownDynamicArgs.from_dict({**_hex_json.loads(\"{\\\"dataframe_column\\\":\\\"Year\\\",\\\"ui_selected_value\\\":null}\"), **{_hex_json.loads(\"\\\"options_variable\\\"\"):_hex_kernel.variable_or_none(\"years_list\", scope_getter=lambda: globals())}}), app_session_token=_hex_APP_SESSION_TOKEN, python_kernel_init_status=_hex_python_kernel_init_status, hex_timezone=_hex_kernel.variable_or_none(\"hex_timezone\", scope_getter=lambda: globals()))\n\nimport json as _hex_json\n_hex_pks.kernel_execution.input_cell.filled_dynamic_value(args=_hex_types.FilledDynamicValueArgs.from_dict({**_hex_json.loads(\"{\\\"variable_name\\\":\\\"years_list\\\",\\\"dataframe_column\\\":\\\"Year\\\",\\\"max_size\\\":10000,\\\"max_size_in_bytes\\\":5242880}\"), **{_hex_json.loads(\"\\\"variable\\\"\"):_hex_kernel.variable_or_none(\"years_list\", scope_getter=lambda: globals())}}), app_session_token=_hex_APP_SESSION_TOKEN, python_kernel_init_status=_hex_python_kernel_init_status, hex_timezone=_hex_kernel.variable_or_none(\"hex_timezone\", scope_getter=lambda: globals()))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import jinja2\n# raw_query = \"\"\"\n#     select\n#         Year,\n#         \"Disaster Group\",\n#         \"Disaster Subgroup\",\n#         \"Disaster Type\",\n#         \"Disaster Subtype\",\n#         Country,\n#         ISO,\n#         \"Region\",\n#         \"Continent\",\n#         \"Location\",\n#         \"Associated Dis\",\n#         \"Dis Mag Value\",\n#         \"Dis Mag Scale\",\n#         \"Start Year\",\n#         \"Start Month\",\n#         \"Start Day\",\n#         \"End Year\",\n#         \"End Month\",\n#         \"End Day\",\n#         \"Total Deaths\",\n#         \"No Injured\",\n#         \"No Affected\",\n#         \"No Homeless\",\n#         \"Total Affected\",\n#         \"Total Damages ('000 US$)\",\n#         lat,\n#         long\n#     from pd_df\n#     where Country in ({{ countries_selection | array }})\n#     and \"Disaster Type\" in ({{ disasters_type | array }})\n#     and year between {{ start_year }} and {{ end_year }}\n# \"\"\"\n# sql_query = jinja2.Template(raw_query).render(vars())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import jinja2\n# raw_query = \"\"\"\n#     select \n#     sum(\"Total Deaths\") as sum_death\n#     from disasters_df\n# \"\"\"\n# sql_query = jinja2.Template(raw_query).render(vars())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import jinja2\n# raw_query = \"\"\"\n#     select \n#     sum(\"Total Affected\") as sum_affected\n#     from disasters_df\n# \"\"\"\n# sql_query = jinja2.Template(raw_query).render(vars())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import jinja2\n# raw_query = \"\"\"\n#     select \n#     sum(\"Total Damages ('000 US$)\") as sum_damages\n#     from disasters_df\n# \"\"\"\n# sql_query = jinja2.Template(raw_query).render(vars())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"death_toll","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"affected_toll","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"damages_toll","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import jinja2\n# raw_query = \"\"\"\n#     select\n#         country,\n#         sum(\"Total Deaths\") as sum_death,\n#         sum(\"Total Affected\") as sum_affected,\n#         count(\"Disaster Type\") as disasters_count,\n#         max(lat) as lat, \n#         max(long) as long,\n#     from disasters_df\n#     group by \"Country\"\n# \"\"\"\n# sql_query = jinja2.Template(raw_query).render(vars())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import altair\nchart_disasters_df = altair.Chart.from_json(\"\"\"\n{\n    \"width\": 500,\n    \"height\": 500,\n    \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n    \"layer\": [\n        {\n            \"resolve\": {\n                \"scale\": {\n                    \"color\": \"independent\",\n                    \"y\": \"shared\"\n                }\n            },\n            \"layer\": [\n                {\n                    \"transform\": [\n                        {\n                            \"filter\": \"isValid(datum[\\\"Year\\\"])\"\n                        }\n                    ],\n                    \"layer\": [\n                        {\n                            \"mark\": {\n                                \"type\": \"line\",\n                                \"point\": false,\n                                \"clip\": true\n                            },\n                            \"params\": [\n                                {\n                                    \"name\": \"interval_intervalselection_\",\n                                    \"select\": {\n                                        \"type\": \"interval\",\n                                        \"encodings\": [\n                                            \"x\"\n                                        ],\n                                        \"translate\": false,\n                                        \"zoom\": false,\n                                        \"mark\": {\n                                            \"fill\": \"#669EFF\",\n                                            \"fillOpacity\": 0.07,\n                                            \"stroke\": \"#669EFF\",\n                                            \"strokeOpacity\": 0.4\n                                        }\n                                    }\n                                },\n                                {\n                                    \"name\": \"legend_pointselection_\",\n                                    \"select\": {\n                                        \"type\": \"point\",\n                                        \"encodings\": [\n                                            \"color\"\n                                        ]\n                                    },\n                                    \"bind\": \"legend\",\n                                    \"value\": []\n                                }\n                            ],\n                            \"encoding\": {\n                                \"opacity\": {\n                                    \"value\": 1\n                                }\n                            }\n                        },\n                        {\n                            \"mark\": {\n                                \"type\": \"point\",\n                                \"filled\": true\n                            },\n                            \"encoding\": {\n                                \"size\": {\n                                    \"value\": 50\n                                },\n                                \"opacity\": {\n                                    \"condition\": {\n                                        \"test\": {\n                                            \"not\": {\n                                                \"and\": [\n                                                    {\n                                                        \"param\": \"legend_pointselection_\",\n                                                        \"empty\": false\n                                                    }\n                                                ]\n                                            },\n                                            \"empty\": false\n                                        },\n                                        \"value\": 0\n                                    },\n                                    \"value\": 1\n                                }\n                            }\n                        },\n                        {\n                            \"mark\": {\n                                \"type\": \"point\",\n                                \"clip\": true\n                            },\n                            \"encoding\": {\n                                \"opacity\": {\n                                    \"value\": 0,\n                                    \"condition\": {\n                                        \"param\": \"pivot_hover_ea30205b-c6bc-4676-b521-18fd25b1475c\",\n                                        \"value\": 1,\n                                        \"empty\": false\n                                    }\n                                },\n                                \"size\": {\n                                    \"value\": 80\n                                }\n                            }\n                        }\n                    ],\n                    \"encoding\": {\n                        \"x\": {\n                            \"field\": \"Year\",\n                            \"type\": \"quantitative\",\n                            \"title\": \"Year\",\n                            \"scale\": {},\n                            \"axis\": {\n                                \"grid\": true,\n                                \"ticks\": true,\n                                \"labels\": true,\n                                \"labelFlush\": false\n                            }\n                        },\n                        \"y\": {\n                            \"field\": \"Disaster Type\",\n                            \"type\": \"quantitative\",\n                            \"aggregate\": \"count\",\n                            \"title\": \"Count of Records\",\n                            \"scale\": {},\n                            \"axis\": {\n                                \"grid\": true,\n                                \"ticks\": true,\n                                \"labels\": true,\n                                \"labelFlush\": false\n                            }\n                        },\n                        \"color\": {\n                            \"field\": \"Disaster Type\",\n                            \"scale\": {\n                                \"range\": [\n                                    \"#4C78A8\",\n                                    \"#F58518\",\n                                    \"#E45756\",\n                                    \"#72B7B2\",\n                                    \"#54A24B\",\n                                    \"#EECA3B\",\n                                    \"#B279A2\",\n                                    \"#FF9DA6\",\n                                    \"#9D755D\",\n                                    \"#BAB0AC\"\n                                ]\n                            },\n                            \"legend\": {\n                                \"symbolOpacity\": 1,\n                                \"symbolType\": \"stroke\"\n                            },\n                            \"title\": \"Disaster Type\"\n                        }\n                    }\n                },\n                {\n                    \"transform\": [\n                        {\n                            \"pivot\": \"Disaster Type\",\n                            \"value\": \"Disaster Type\",\n                            \"op\": \"count\",\n                            \"groupby\": [\n                                \"Year\"\n                            ]\n                        }\n                    ],\n                    \"layer\": [\n                        {\n                            \"mark\": {\n                                \"type\": \"rule\",\n                                \"clip\": true\n                            },\n                            \"encoding\": {\n                                \"opacity\": {\n                                    \"condition\": {\n                                        \"value\": 0.3,\n                                        \"param\": \"pivot_hover_ea30205b-c6bc-4676-b521-18fd25b1475c\",\n                                        \"empty\": false\n                                    },\n                                    \"value\": 0\n                                },\n                                \"color\": {\n                                    \"value\": \"CHART_DEFAULT_RULE_COLOR_MARKER\"\n                                },\n                                \"tooltip\": [\n                                    {\n                                        \"field\": \"Year\",\n                                        \"type\": \"quantitative\"\n                                    }\n                                ],\n                                \"y\": null\n                            },\n                            \"params\": [\n                                {\n                                    \"name\": \"pivot_hover_ea30205b-c6bc-4676-b521-18fd25b1475c\",\n                                    \"select\": {\n                                        \"type\": \"point\",\n                                        \"fields\": [\n                                            \"Year\"\n                                        ],\n                                        \"nearest\": true,\n                                        \"on\": \"mouseover\",\n                                        \"clear\": \"mouseout\"\n                                    }\n                                }\n                            ]\n                        }\n                    ],\n                    \"encoding\": {\n                        \"x\": {\n                            \"field\": \"Year\",\n                            \"type\": \"quantitative\",\n                            \"title\": \"Year\",\n                            \"scale\": {},\n                            \"axis\": {\n                                \"grid\": true,\n                                \"ticks\": true,\n                                \"labels\": true,\n                                \"labelFlush\": false\n                            }\n                        }\n                    }\n                },\n                {\n                    \"transform\": [\n                        {\n                            \"aggregate\": [],\n                            \"groupby\": [\n                                \"Disaster Type\"\n                            ]\n                        },\n                        {\n                            \"window\": [\n                                {\n                                    \"op\": \"rank\",\n                                    \"as\": \"rank\"\n                                }\n                            ]\n                        },\n                        {\n                            \"filter\": \"datum.rank <= 21\"\n                        }\n                    ],\n                    \"mark\": {\n                        \"type\": \"rule\",\n                        \"clip\": true\n                    },\n                    \"name\": \"aggregate_color_spec_ea30205b_c6bc_4676_b521_18fd25b1475c\",\n                    \"encoding\": {\n                        \"opacity\": {\n                            \"value\": 0\n                        }\n                    }\n                },\n                {\n                    \"name\": \"__drilldown_dataset\",\n                    \"mark\": {\n                        \"type\": \"point\",\n                        \"opacity\": 0\n                    },\n                    \"transform\": [\n                        {\n                            \"filter\": {\n                                \"param\": \"interval_intervalselection_\"\n                            }\n                        },\n                        {\n                            \"filter\": {\n                                \"param\": \"legend_pointselection_\"\n                            }\n                        }\n                    ]\n                }\n            ]\n        }\n    ],\n    \"resolve\": {\n        \"scale\": {}\n    },\n    \"datasets\": {\n        \"layer00\": [\n            {\n                \"name\": \"dummy\",\n                \"value\": 0\n            }\n        ]\n    },\n    \"config\": {\n        \"legend\": {\n            \"orient\": \"bottom\"\n        }\n    },\n    \"usermeta\": {\n        \"selectionConfigs\": {\n            \"interval_intervalselection_\": {\n                \"type\": \"interval\",\n                \"datetimeFields\": []\n            },\n            \"legend_pointselection_\": {\n                \"type\": \"point\",\n                \"datetimeFields\": []\n            }\n        }\n    }\n}\n\"\"\")\nchart_disasters_df.datasets.layer00 = disasters_df.to_json(orient='records')\nchart_disasters_df.display(actions=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}],"metadata":{"orig_nbformat":4,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"hex_info":{"author":"Carlos Escobar","project_id":"ed7149ad-9ca0-4662-a838-a0ec735ec38b","version":"draft","exported_date":"Sun Jun 11 2023 00:29:14 GMT+0000 (Coordinated Universal Time)"}},"nbformat":4,"nbformat_minor":4}